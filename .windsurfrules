# From README.md:

# AIModels

A collection of AI model specifications across different providers. This package provides normalized data about AI models, including their capabilities, context windows, and pricing information.

## Installation

```bash
npm install aimodels
```

## Usage

```typescript
import { models } from 'aimodels';

// Find models by capability
const chatModels = models.can('chat');
const multimodalModels = models.can('chat', 'img-in');

// Find models by provider
const openaiModels = models.fromProvider('openai');

// Find models by creator
const metaModels = models.fromCreator('meta');

// Find models by context window
const largeContextModels = models.withMinContext(32768);

// Find specific model
const model = models.id('gpt-4');
console.log(model?.context.total); // Context window size
console.log(model?.providers); // ['openai']
```

## Features

- Comprehensive database of AI models from major providers (OpenAI, Anthropic, Mistral, etc.)
- Normalized data structure for easy comparison
- Model capabilities (chat, img-in, img-out, function-out, etc.)
- Context window information
- Creator and provider associations
- TypeScript support with full type safety
- Zero dependencies
- Universal JavaScript support (Node.js, browsers, Deno)
- Regular updates with new models

## Types

### Model
```typescript
interface Model {
  /** Unique identifier */
  id: string;
  /** Display name */
  name: string;
  /** Model capabilities */
  can: Capability[];
  /** Available providers */
  providers: string[];
  /** Context window information */
  context: ModelContext;
  /** License or creator */
  license: string;
}
```

### Capabilities
```typescript
type Capability =
  | "chat"         // shortcut for "text-in" and "text-out"
  | "reason"       // when the model spends some tokens on reasoning
  | "text-in"      // process text input
  | "text-out"     // output text
  | "img-in"       // understand images
  | "img-out"      // generate images
  | "sound-in"     // process audio input
  | "sound-out"    // generate audio/speech
  | "json-out"     // structured JSON output
  | "function-out" // function calling
  | "vectors-out"; // output vector embeddings
```

For more detailed information, see:
- [Model Capabilities](/docs/model-capabilities.md)
- [Model Structure](/docs/model-structure.md)
- [Providers](/docs/providers.md)

## License

MIT
---

# From docs/rules-for-ai.md:

# Rules for AI

## TLDR Context
It's an NPM package at https://www.npmjs.com/package/aimodels
Can run both in browsers, Node.js, and Deno
Used in other libraries like https://www.npmjs.com/package/aiwrapper and as a source of truth on https://aiwrapper.dev

## Test often
After a big change or before committing, do "npm test"

## Commit messages
Short and concise.
Add "<scope>: <description>" suffix.

## Update these rules
When you change README.md or docs/rules-for-ai.md, run "npm run gen-ai-rules"
---

# From docs/providers.md:

# Providers

This document outlines how provider information is structured in the `aimodels` package.

## TypeScript Definition

```typescript
interface Provider {
  /** Provider identifier */
  id: string;
  /** Display name */
  name: string;
  /** Provider's website URL */
  websiteUrl: string;
  /** API documentation URL */
  apiUrl: string;
  /** Pricing information for models */
  models: Record<string, ModelPrice>;
}

interface ModelPrice {
  /** Price type (token, image, audio) */
  type: string;
  /** Price per million input tokens (for token-based models) */
  input?: number;
  /** Price per million output tokens (for token-based models) */
  output?: number;
  /** Price per image (for image-based models) */
  price?: number;
  /** Image size (for image-based models) */
  size?: string;
}
```

## Example Usage

```typescript
// Find models from a specific provider
const openaiModels = models.fromProvider('openai');

// Check if a model is available from multiple providers
const gpt4 = models.id('gpt-4');
console.log(gpt4?.providers); // ['openai', 'azure']

// Get all providers that offer a specific model
const providers = gpt4?.providers ?? [];
```

## Example Provider Data

```json
{
  "id": "openai",
  "name": "OpenAI",
  "websiteUrl": "https://openai.com",
  "apiUrl": "https://platform.openai.com/docs/api-reference",
  "models": {
    "gpt-4": {
      "type": "token",
      "input": 0.03,
      "output": 0.06
    },
    "gpt-3.5-turbo": {
      "type": "token",
      "input": 0.0015,
      "output": 0.002
    },
    "dall-e-3": {
      "type": "image",
      "price": 0.04,
      "size": "1024x1024"
    }
  }
}
```
---

# From docs/model-structure.md:

# Model Data Structure

This document outlines the standardized structure for representing AI models in the `aimodels` package.

## Core Structure

```typescript
interface Model {
  /** Unique identifier for the model */
  id: string;

  /** Display name for the model */
  name: string;

  /** Model capabilities */
  can: Capability[];

  /** Available providers */
  providers: string[];

  /** License or creator information */
  license: string;

  /** Context window information */
  context: ModelContext;
}
```

## Example

```json
{
  "id": "gpt-4-vision-preview",
  "name": "GPT-4V",
  "license": "openai",
  "providers": ["openai", "azure"],
  "can": [
    "chat",
    "img-in",
    "json-out",
    "function-out"
  ],

  "context": {
    "total": 128000,
    "maxOutput": 4000
  }
}
```

## Field Descriptions

### Core Metadata
- **id**: Unique identifier for the model
- **name**: Display name for the model
- **creator**: Organization that created the model
- **license**: License type (e.g., "proprietary", "apache-2.0", "mit", "llama-2-community")
- **providers**: Array of provider IDs that can serve this model

### Capabilities
See [model-capabilities.md](./model-capabilities.md) for detailed documentation.
```json
"can": ["chat", "img-in", "json-out"]
```

### Context Window
```json
"context": {
  "total": 128000,        // maximum input tokens
  "maxOutput": 4000,      // maximum output tokens
  "outputIsFixed": 1      // optional, for models with fixed output limit
}
```

## Examples

### Proprietary Multi-Provider Model
```json
{
  "id": "gpt-4-vision-preview",
  "name": "GPT-4V",
  "creator": "OpenAI",
  "license": "proprietary",
  "providers": ["openai", "azure"],
  "can": ["chat", "img-in", "json-out", "function-out"],
  "context": {
    "total": 128000,
    "maxOutput": 4000
  }
}
```

### Open Source Model
```json
{
  "id": "llama-2-70b-chat",
  "name": "Llama 2 70B Chat",
  "creator": "Meta",
  "license": "llama-2-community",
  "providers": [
    "replicate",
    "ollama",
    "together",
    "anyscale"
  ],
  "can": ["chat", "function-out"],
  "context": {
    "total": 4096,
    "maxOutput": 4096
  }
}
```

### Image Generation Model
```json
{
  "id": "stable-diffusion-xl",
  "name": "Stable Diffusion XL",
  "creator": "Stability AI",
  "license": "openrail++",
  "providers": [
    "replicate",
    "stability",
    "ollama",
    "huggingface"
  ],
  "can": ["img-out"]
}
```

## Design Rationale

1. **Multi-provider Support**: Models can be served by multiple providers (e.g., OpenAI models through Azure)
2. **Capability-based**: Uses the intuitive "can" system for declaring model capabilities
3. **License Tracking**: Includes licensing information for compliance and filtering
4. **Context Management**: Clear specification of context window limitations
5. **Extensible**: Structure can accommodate new model types and capabilities

## Implementation Notes

- All string fields should use kebab-case
- Provider IDs should match those in the providers configuration
- Capabilities should match the standardized list in model-capabilities.md
- Context window values are in tokens
- Pricing information is stored separately in provider configurations
---

# From docs/model-capabilities.md:

# Model Capabilities

This document outlines the capabilities system used in the `aimodels` package to describe what AI models can do.

## TypeScript Definition

```typescript
type Capability =
  | "chat"         // shortcut for "text-in" and "text-out"
  | "reason"       // when the model spends some tokens on reasoning
  | "text-in"      // process text input
  | "text-out"     // output text
  | "img-in"       // understand images
  | "img-out"      // generate images
  | "sound-in"     // process audio input
  | "sound-out"    // generate audio/speech
  | "json-out"     // structured JSON output
  | "function-out" // function calling
  | "vectors-out"; // output vector embeddings
```

## Example Usage

```typescript
// Find models that can chat
const chatModels = models.can("chat");

// Find models that can process images and chat
const visionModels = models.can("chat", "img-in");

// Find models that can generate images
const imageGenerators = models.can("img-out");

// Find models that can do function calling
const functionModels = models.can("function-out");
```
```

## Examples by Model Type

### Multimodal Chat Models (GPT-4V, Claude 3)

```json
{
  "can": ["chat", "text-in", "img-in", "json-out", "function-out"]
}
```

### Image Generation Models (DALL-E 3, Stable Diffusion)

```json
{
  "can": ["text-in", "img-out"]
}
```

### Speech Models (Whisper)

```json
{
  "can": ["sound-in", "text-out"]
}
```

### Text-to-Speech Models (ElevenLabs)

```json
{
  "can": ["text-in", "sound-out"]
}
```

### Embedding Models (CLIP)

```json
{
  "can": ["text-in", "img-in", "vectors-out"]
}
```

## Using in Code

```typescript
// Type definitions
type Capability =
  | "chat"
  | "img-in"
  | "img-out"
  | "sound-in"
  | "sound-out"
  | "json-out"
  | "function-out"
  | "text-to-vec"
  | "img-to-vec"
  | "reason"
  | "text-in";

interface Model {
  can: (...capabilities: Capability[]) => boolean;
}

// Usage examples
// Check single capability
if (model.can("chat")) {
  // use for chat
}

// Check multiple capabilities
if (model.can("img-in", "json-out")) {
  // use for image analysis with structured output
}

// Filter models
const imageModels = models.filter((m) => m.can("img-in"));
const multimodal = models.filter((m) => m.can("chat", "img-in"));
```

## Capability Descriptions

- **chat**: Text generation and understanding, including code
- **img-in**: Process and understand images
- **img-out**: Generate images
- **sound-in**: Process audio input and speech recognition
- **sound-out**: Generate audio and speech
- **json-out**: Generate structured JSON output
- **function-out**: Handle function calling and API interactions
- **text-to-vec**: Generate text embeddings
- **img-to-vec**: Generate image embeddings

## Design Rationale

1. **Simple API**: Using "can" makes the API intuitive and readable
2. **Concise JSON**: Shorter property name reduces data size
3. **Natural Language**: Reads naturally in code: `model.can("chat")`
4. **Input/Output Pattern**: Uses intuitive "-in" and "-out" suffixes
5. **Vector Operations**: Special "-to-vec" suffix for embeddings
6. **Extensibility**: Easy to add new capabilities following the pattern

## Implementation Notes

- Models can have multiple capabilities
- Capabilities are represented as an array of strings
- All capability strings are lowercase with hyphen separators
- The `can()` method supports checking multiple capabilities
- Type system ensures valid capability strings